{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd \n",
    "import numpy\n",
    "import matplotlib.pyplot as plt \n",
    "from pyspark.sql import SparkSession# create sparksession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"RecruitRestaurantVisitorForecasting\").config(\"spark.local.dir\",\"/home/jovyan/work\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Air Reserve Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 1.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = spark.read.csv(\"../data/air_reserve.csv.gz\", header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+----------------+\n",
      "|        air_store_id|     visit_datetime|   reserve_datetime|reserve_visitors|\n",
      "+--------------------+-------------------+-------------------+----------------+\n",
      "|air_877f79706adbfb06|2016-01-01 19:00:00|2016-01-01 16:00:00|               1|\n",
      "|air_db4b38ebe7a7ceff|2016-01-01 19:00:00|2016-01-01 19:00:00|               3|\n",
      "|air_db4b38ebe7a7ceff|2016-01-01 19:00:00|2016-01-01 19:00:00|               6|\n",
      "|air_877f79706adbfb06|2016-01-01 20:00:00|2016-01-01 16:00:00|               2|\n",
      "|air_db80363d35f10926|2016-01-01 20:00:00|2016-01-01 01:00:00|               5|\n",
      "+--------------------+-------------------+-------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- air_store_id: string (nullable = true)\n",
      " |-- visit_datetime: timestamp (nullable = true)\n",
      " |-- reserve_datetime: timestamp (nullable = true)\n",
      " |-- reserve_visitors: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+----------------+\n",
      "|        air_store_id|     visit_datetime|   reserve_datetime|reserve_visitors|\n",
      "+--------------------+-------------------+-------------------+----------------+\n",
      "|air_877f79706adbfb06|2016-01-01 19:00:00|2016-01-01 16:00:00|               1|\n",
      "|air_db4b38ebe7a7ceff|2016-01-01 19:00:00|2016-01-01 19:00:00|               3|\n",
      "|air_db4b38ebe7a7ceff|2016-01-01 19:00:00|2016-01-01 19:00:00|               6|\n",
      "|air_877f79706adbfb06|2016-01-01 20:00:00|2016-01-01 16:00:00|               2|\n",
      "|air_db80363d35f10926|2016-01-01 20:00:00|2016-01-01 01:00:00|               5|\n",
      "+--------------------+-------------------+-------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"ar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_stat = spark.sql(\"\"\"\n",
    "select air_store_id\n",
    "     , to_date(visit_datetime) as visit_date\n",
    "     , sum( unix_timestamp(visit_datetime)- unix_timestamp(reserve_datetime)/3600 ) as rs1\n",
    "     , sum(reserve_visitors) as rv1\n",
    "     , avg( unix_timestamp(visit_datetime)- unix_timestamp(reserve_datetime)/3600 ) as rs2\n",
    "     , avg(reserve_visitors) as rv2   \n",
    "from ar group by 1,2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------------+---+--------------------+------------------+\n",
      "|        air_store_id|visit_date|            rs1|rv1|                 rs2|               rv2|\n",
      "+--------------------+----------+---------------+---+--------------------+------------------+\n",
      "|air_32460819c7600037|2016-01-13|  4.356935221E9| 17|1.4523117403333333E9| 5.666666666666667|\n",
      "|air_7831b00996701c0f|2016-01-22|  4.359249633E9| 23|       1.453083211E9| 7.666666666666667|\n",
      "|air_54ed43163b7596c4|2016-01-25|  1.453341077E9|  8|       1.453341077E9|               8.0|\n",
      "|air_2a3743e37aab04b4|2016-02-05|  4.362866499E9|  8|       1.454288833E9|2.6666666666666665|\n",
      "|air_8093d0b565e9dbdf|2016-02-17|1.1642632051E10| 19|    1.455329006375E9|             2.375|\n",
      "+--------------------+----------+---------------+---+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ar_stat.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 10 ms, total: 10 ms\n",
      "Wall time: 23.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hpg = spark.read.csv(\"../data/hpg_reserve.csv.gz\", header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hpg_store_id: string (nullable = true)\n",
      " |-- visit_datetime: timestamp (nullable = true)\n",
      " |-- reserve_datetime: timestamp (nullable = true)\n",
      " |-- reserve_visitors: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hpg.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+----------------+\n",
      "|        hpg_store_id|     visit_datetime|   reserve_datetime|reserve_visitors|\n",
      "+--------------------+-------------------+-------------------+----------------+\n",
      "|hpg_c63f6f42e088e50f|2016-01-01 11:00:00|2016-01-01 09:00:00|               1|\n",
      "|hpg_dac72789163a3f47|2016-01-01 13:00:00|2016-01-01 06:00:00|               3|\n",
      "|hpg_c8e24dcf51ca1eb5|2016-01-01 16:00:00|2016-01-01 14:00:00|               2|\n",
      "|hpg_24bb207e5fd49d4a|2016-01-01 17:00:00|2016-01-01 11:00:00|               5|\n",
      "|hpg_25291c542ebb3bc2|2016-01-01 17:00:00|2016-01-01 03:00:00|              13|\n",
      "+--------------------+-------------------+-------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hpg.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = spark.read.csv(\"../data/store_id_relation.csv.gz\", header='true',inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- air_store_id: string (nullable = true)\n",
      " |-- hpg_store_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "link.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|        air_store_id|        hpg_store_id|\n",
      "+--------------------+--------------------+\n",
      "|air_63b13c56b7201bd9|hpg_4bc649e72e2a239a|\n",
      "|air_a24bf50c3e90d583|hpg_c34b496d0305a809|\n",
      "|air_c7f78b4f3cba33ff|hpg_cd8ae0d9bbd58ff9|\n",
      "|air_947eb2cae4f3e8f2|hpg_de24ea49dc25d6b8|\n",
      "|air_965b2e0cf4119003|hpg_653238a84804d8e7|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "link.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpg = hpg.alias('m').join(link.alias('h'), hpg.hpg_store_id == link.hpg_store_id).select('h.air_store_id','m.*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+-------------------+----------------+\n",
      "|        air_store_id|        hpg_store_id|     visit_datetime|   reserve_datetime|reserve_visitors|\n",
      "+--------------------+--------------------+-------------------+-------------------+----------------+\n",
      "|air_db80363d35f10926|hpg_878cc70b1abc76f7|2016-01-01 19:00:00|2016-01-01 15:00:00|               4|\n",
      "|air_08cb3c4ee6cd6a22|hpg_dc639640420bde5f|2016-01-01 19:00:00|2016-01-01 16:00:00|               2|\n",
      "|air_6b15edd1b4fbb96a|hpg_babe2c3d962d7bb6|2016-01-02 17:00:00|2016-01-01 22:00:00|               3|\n",
      "|air_37189c92b6c761ec|hpg_2e10e1956528199a|2016-01-02 18:00:00|2016-01-02 17:00:00|               2|\n",
      "|air_37189c92b6c761ec|hpg_2e10e1956528199a|2016-01-02 18:00:00|2016-01-01 20:00:00|               2|\n",
      "|air_37189c92b6c761ec|hpg_2e10e1956528199a|2016-01-02 18:00:00|2016-01-01 21:00:00|               3|\n",
      "|air_c1ff20617c54fee7|hpg_4be4a5cb851e45af|2016-01-02 18:00:00|2016-01-02 16:00:00|               2|\n",
      "|air_7420042ff75f9aca|hpg_7459535472b27200|2016-01-02 18:00:00|2016-01-01 12:00:00|               7|\n",
      "|air_1033310359ceeac1|hpg_8072ff2fb418e273|2016-01-02 18:00:00|2016-01-02 14:00:00|               2|\n",
      "|air_375a5241615b5e22|hpg_a284bcfadc49db95|2016-01-02 18:00:00|2016-01-02 12:00:00|               8|\n",
      "|air_6b15edd1b4fbb96a|hpg_babe2c3d962d7bb6|2016-01-02 18:00:00|2016-01-01 12:00:00|               3|\n",
      "|air_6b15edd1b4fbb96a|hpg_babe2c3d962d7bb6|2016-01-02 18:00:00|2016-01-01 12:00:00|               3|\n",
      "|air_37189c92b6c761ec|hpg_2e10e1956528199a|2016-01-02 19:00:00|2016-01-01 21:00:00|               6|\n",
      "|air_db80363d35f10926|hpg_878cc70b1abc76f7|2016-01-02 19:00:00|2016-01-02 14:00:00|               2|\n",
      "|air_8e492076a1179383|hpg_aee92538e1b51d5f|2016-01-02 19:00:00|2016-01-01 22:00:00|               3|\n",
      "|air_08cb3c4ee6cd6a22|hpg_dc639640420bde5f|2016-01-02 19:00:00|2016-01-02 09:00:00|               2|\n",
      "|air_08cb3c4ee6cd6a22|hpg_dc639640420bde5f|2016-01-02 19:00:00|2016-01-01 23:00:00|               4|\n",
      "|air_37189c92b6c761ec|hpg_2e10e1956528199a|2016-01-02 21:00:00|2016-01-02 14:00:00|               7|\n",
      "|air_6c91a28278a16f64|hpg_945c2807cef88022|2016-01-03 13:00:00|2016-01-01 21:00:00|               4|\n",
      "|air_6e3fd96320d24324|hpg_3f89e343b3e1d336|2016-01-03 17:00:00|2016-01-02 11:00:00|               4|\n",
      "+--------------------+--------------------+-------------------+-------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hpg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpg.createOrReplaceTempView(\"hpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+-------------------+----------------+\n",
      "|        air_store_id|        hpg_store_id|     visit_datetime|   reserve_datetime|reserve_visitors|\n",
      "+--------------------+--------------------+-------------------+-------------------+----------------+\n",
      "|air_db80363d35f10926|hpg_878cc70b1abc76f7|2016-01-01 19:00:00|2016-01-01 15:00:00|               4|\n",
      "+--------------------+--------------------+-------------------+-------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from hpg limit 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "hpg_stat = spark.sql(\"\"\"\n",
    "select air_store_id\n",
    "     , to_date(visit_datetime) as visit_date\n",
    "     , sum( unix_timestamp(visit_datetime)- unix_timestamp(reserve_datetime)/3600 ) as rs1\n",
    "     , sum(reserve_visitors) as rv1\n",
    "     , avg( unix_timestamp(visit_datetime)- unix_timestamp(reserve_datetime)/3600 ) as rs2\n",
    "     , avg(reserve_visitors) as rv2   \n",
    "from hpg group by 1,2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[air_store_id: string, visit_date: date, rs1: double, rv1: bigint, rs2: double, rv2: double]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpg_stat.cache()\n",
    "ar_stat.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.read.csv(\"../data/air_visit_data.csv\", header='true',inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------+\n",
      "|        air_store_id|         visit_date|visitors|\n",
      "+--------------------+-------------------+--------+\n",
      "|air_ba937bf13d40fb24|2016-01-13 00:00:00|      25|\n",
      "|air_ba937bf13d40fb24|2016-01-14 00:00:00|      32|\n",
      "|air_ba937bf13d40fb24|2016-01-15 00:00:00|      29|\n",
      "+--------------------+-------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView(\"train\")\n",
    "hpg_stat.createOrReplaceTempView(\"hpg_stat\")\n",
    "ar_stat.createOrReplaceTempView(\"ar_stat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = spark.sql(\"\"\"\n",
    "select t.*, a.rs1 as rs1_x, a.rv1 as rv1_x, a.rs2 as rs2_x, a.rv2 as rv2_x\n",
    ", h.rs1 as rs1_y, h.rv1 as rv1_y, h.rs2 as rs2_y, h.rv2 as rv2_y \n",
    "FROM train t left join hpg_stat h on (t.air_store_id  = h.air_store_id and t.visit_date = h.visit_date)\n",
    "LEFT JOIN ar_stat a on (t.air_store_id  = a.air_store_id and t.visit_date = a.visit_date)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|        air_store_id|         visit_date|visitors|rs1_x|rv1_x|rs2_x|rv2_x|rs1_y|rv1_y|rs2_y|rv2_y|\n",
      "+--------------------+-------------------+--------+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|air_ba937bf13d40fb24|2016-01-13 00:00:00|      25| null| null| null| null| null| null| null| null|\n",
      "|air_ba937bf13d40fb24|2016-01-14 00:00:00|      32| null| null| null| null| null| null| null| null|\n",
      "|air_ba937bf13d40fb24|2016-01-15 00:00:00|      29| null| null| null| null| null| null| null| null|\n",
      "|air_ba937bf13d40fb24|2016-01-16 00:00:00|      22| null| null| null| null| null| null| null| null|\n",
      "|air_ba937bf13d40fb24|2016-01-18 00:00:00|       6| null| null| null| null| null| null| null| null|\n",
      "+--------------------+-------------------+--------+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.toPandas()\n",
    "\n",
    "train_df.to_csv('../data/to2ml/round2_train.csv.gz',compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.read.csv(\"../data/sample_submission.csv.gz\", header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+--------+\n",
      "|id                             |visitors|\n",
      "+-------------------------------+--------+\n",
      "|air_00a91d42b08b08d9_2017-04-23|0       |\n",
      "|air_00a91d42b08b08d9_2017-04-24|0       |\n",
      "|air_00a91d42b08b08d9_2017-04-25|0       |\n",
      "+-------------------------------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(3,truncate=False)\n",
    "\n",
    "test.createOrReplaceTempView(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsplit_part(s, sep, part_num):\n",
    "    return s.rsplit(sep,1)[part_num - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.udf.register('rsplit_part',rsplit_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|air_store_id        |visit_date|\n",
      "+--------------------+----------+\n",
      "|air_00a91d42b08b08d9|2017-04-23|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select rsplit_part(id,'_',1) as air_store_id,to_date(rsplit_part(id,'_',2)) as visit_date  from test limit 1\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = spark.sql(\"\"\"\n",
    "select t.*, a.rs1 as rs1_x, a.rv1 as rv1_x, a.rs2 as rs2_x, a.rv2 as rv2_x\n",
    ", h.rs1 as rs1_y, h.rv1 as rv1_y, h.rs2 as rs2_y, h.rv2 as rv2_y \n",
    "FROM (select rsplit_part(id,'_',1) as air_store_id,to_date(rsplit_part(id,'_',2)) as visit_date  from test) t left join hpg_stat h on (t.air_store_id  = h.air_store_id and t.visit_date = h.visit_date)\n",
    "LEFT JOIN ar_stat a on (t.air_store_id  = a.air_store_id and t.visit_date = a.visit_date)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test.toPandas()\n",
    "\n",
    "test_df.to_csv('../data/to2ml/round2_test.csv.gz',compression='gzip',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
